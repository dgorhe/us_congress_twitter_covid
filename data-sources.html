<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Data sources | US Congress - Tweets and COVID-19</title>
  <meta name="description" content="Chapter 2 Data sources | US Congress - Tweets and COVID-19" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Data sources | US Congress - Tweets and COVID-19" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Data sources | US Congress - Tweets and COVID-19" />
  
  
  

<meta name="author" content="Darvesh Gorhe, Thomas Holvoet, Nicolo Ricci" />


<meta name="date" content="2021-12-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="data-transformation.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/parallel-coordinates-2.1.8/parcoords.css" rel="stylesheet" />
<script src="libs/parcoords-binding-1.0.0/parcoords.js"></script>
<script src="libs/d3-5.16.0/d3.min.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">US Congress Tweet Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#congress-and-mobility"><i class="fa fa-check"></i><b>1.1</b> Congress and Mobility</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#congress-and-sentiment"><i class="fa fa-check"></i><b>1.2</b> Congress and Sentiment</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-sources.html"><a href="data-sources.html"><i class="fa fa-check"></i><b>2</b> Data sources</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-sources.html"><a href="data-sources.html#congress-members-tweets"><i class="fa fa-check"></i><b>2.1</b> Congress Members Tweets</a></li>
<li class="chapter" data-level="2.2" data-path="data-sources.html"><a href="data-sources.html#googles-changes-in-mobility-data"><i class="fa fa-check"></i><b>2.2</b> Google’s Changes in Mobility Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-sources.html"><a href="data-sources.html#number-of-tweets-cases-and-mobility"><i class="fa fa-check"></i><b>2.3</b> Number of tweets cases and mobility</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-transformation.html"><a href="data-transformation.html"><i class="fa fa-check"></i><b>3</b> Data transformation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-transformation.html"><a href="data-transformation.html#congress-members-tweets-1"><i class="fa fa-check"></i><b>3.1</b> Congress Members Tweets</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="data-transformation.html"><a href="data-transformation.html#tweet-cleaning-process"><i class="fa fa-check"></i><b>3.1.1</b> Tweet Cleaning Process</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-transformation.html"><a href="data-transformation.html#appending-zero-shot-classification-labels"><i class="fa fa-check"></i><b>3.1.2</b> Appending Zero Shot Classification Labels</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-transformation.html"><a href="data-transformation.html#googles-changes-in-mobility-data-1"><i class="fa fa-check"></i><b>3.2</b> Google’s Changes in Mobility Data</a></li>
<li class="chapter" data-level="3.3" data-path="data-transformation.html"><a href="data-transformation.html#number-of-tweets-cases-and-mobility-1"><i class="fa fa-check"></i><b>3.3</b> Number of tweets cases and mobility</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>4</b> Missing values</a>
<ul>
<li class="chapter" data-level="4.1" data-path="missing-values.html"><a href="missing-values.html#excluding-tweet-content-from-missing-values"><i class="fa fa-check"></i><b>4.1</b> Excluding Tweet Content from Missing Values</a></li>
<li class="chapter" data-level="4.2" data-path="missing-values.html"><a href="missing-values.html#geo"><i class="fa fa-check"></i><b>4.2</b> Geo</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="missing-values.html"><a href="missing-values.html#impact-of-missing-geo-values"><i class="fa fa-check"></i><b>4.2.1</b> Impact of Missing Geo Values</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="missing-values.html"><a href="missing-values.html#language"><i class="fa fa-check"></i><b>4.3</b> Language</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="missing-values.html"><a href="missing-values.html#impact-of-missing-lang-values"><i class="fa fa-check"></i><b>4.3.1</b> Impact of Missing Lang Values</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="missing-values.html"><a href="missing-values.html#other-columns"><i class="fa fa-check"></i><b>4.4</b> Other Columns</a></li>
<li class="chapter" data-level="4.5" data-path="missing-values.html"><a href="missing-values.html#number-of-tweets-cases-and-mobility-2"><i class="fa fa-check"></i><b>4.5</b> Number of tweets cases and mobility</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>5</b> Results</a></li>
<li class="chapter" data-level="6" data-path="section.html"><a href="section.html"><i class="fa fa-check"></i><b>6</b> <!-- Nicolo's Code START --></a></li>
<li class="chapter" data-level="7" data-path="r-we-filter-the-dataset-to-include-only-usa-this-is-because-we-are-assuming-that-the-majority-of-the-english-language-tweets-we-are-dealing-are-coming-from-usa.-in-data-we-are-storing-the-data-coming-from-httpswww.ecdc.europa.euenpublications-datadownload-todays-data-geographic-distribution-covid-19-cases-worldwide-which-is-recording-the-number-of-cases-and-deaths-ion-every-day-of-2020-by-country.-ignoring-testdata-datadatacountryterritorycodeusa-we-are-going-to-aggregate-our-values-in-ciao1-we-have-the-top-50-bigrams-in-tweets-for-each-day.-so-in-this-case-we-are-grouping-the-tweets-by-each-day-so-that-we-have-a-table-showing-yearmonth-day-and-the-total-number-of-covid-related-bigrams.-we-focused-on-bigrams-so-we-can-catch-the-combination-covid-19-among-others-ciao1_mod-aggregateciao1countsbylistciao1yearciao1monthciao1dayfunsum-we-are-going-to-change-the-columns-name-apparently-when-aggregating-we-are-losing-the-columns-names-colnamesciao1_mod1-year-colnamesciao1_mod2-month-colnamesciao1_mod3-day-colnamesc"><a href="r-we-filter-the-dataset-to-include-only-usa-this-is-because-we-are-assuming-that-the-majority-of-the-english-language-tweets-we-are-dealing-are-coming-from-usa.-in-data-we-are-storing-the-data-coming-from-httpswww.ecdc.europa.euenpublications-datadownload-todays-data-geographic-distribution-covid-19-cases-worldwide-which-is-recording-the-number-of-cases-and-deaths-ion-every-day-of-2020-by-country.-ignoring-testdata-datadatacountryterritorycodeusa-we-are-going-to-aggregate-our-values-in-ciao1-we-have-the-top-50-bigrams-in-tweets-for-each-day.-so-in-this-case-we-are-grouping-the-tweets-by-each-day-so-that-we-have-a-table-showing-yearmonth-day-and-the-total-number-of-covid-related-bigrams.-we-focused-on-bigrams-so-we-can-catch-the-combination-covid-19-among-others-ciao1_mod-aggregateciao1countsbylistciao1yearciao1monthciao1dayfunsum-we-are-going-to-change-the-columns-name-apparently-when-aggregating-we-are-losing-the-columns-names-colnamesciao1_mod1-year-colnamesciao1_mod2-month-colnamesciao1_mod3-day-colnamesc"><i class="fa fa-check"></i><b>7</b> <code>{r} # # we filter the dataset to include only USA, this is because we are assuming that the majority of the english language tweets we are dealing are coming from USA. # # In data we are storing the data coming from https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide # #which is recording the number of cases and deaths ion every day of 2020 by country. #  # # Ignoring # # testdata&lt;-data[data$countryterritoryCode=='USA',] #  # #We are going to aggregate our values, in ciao1 we have the top 50 bigrams in tweets for each day. So in this case we are grouping the tweets by each day, so that we have a table showing year,month, day and the total number of Covid-related bigrams. We focused on bigrams so we can catch the combination COVID 19 among others #  # ciao1_mod&lt;-aggregate(ciao1$counts,by=list(ciao1$year,ciao1$month,ciao1$day),FUN=sum) # #we are going to change the column's name (apparently when aggregating we are losing the columns names) # colnames(ciao1_mod)[1]&lt;-'year' # colnames(ciao1_mod)[2]&lt;-'month' # colnames(ciao1_mod)[3]&lt;-'day' # colnames(ciao1_mod)[4]&lt;-'tweet_counts' #  # #We are going to order our data by date, so we will be able to use a function to get rid of the dates and just use a common column called interval, so that we will be able to test our correlation between different spans of time # #We are going to order both cases and deaths, and tweets by their date # df3&lt;-testdata[order(testdata$year,testdata$month,testdata$day), ] # df3 %&gt;% map_df(rev) # ciao1_mod3&lt;-ciao1_mod[order(ciao1_mod$year,ciao1_mod$month,ciao1_mod$day),] # ciao1_mod3 %&gt;% map_df(rev) # #We are going to create a column interval, so that we can geet rid of the dates and ease up the merging of different tables and for now we set it to 0 # ciao1_mod3$interval=0 # df3$interval=0 # #Now we are going to align the two tables so to have similar periods of time for our analysis. For this purpose we are going to consider the period from 04/1/2021 to the day 12/14/2021 which is the last one in one of the two tables # #To do that we filter our rows in that specific period # df3&lt;-df3[df3$month&gt;=4 &amp; df3$year==2020,] # ciao1_mod3&lt;-ciao1_mod3[ciao1_mod3$month&gt;=4 &amp; ciao1_mod3$year==2020,] # #We find out that the cases and deaths df is only till 12/14/2020 but the tweets is to 12/30 so we are going to eliminate the last 16 rows in our tweets df # n&lt;-dim(ciao1_mod3)[1] # ciao1_mod3&lt;-ciao1_mod3[1:(n-16),] # #We obtained the two datasets cleaned and parsed, the next styep would be to implement a function to create intervals # # Instead of having dates, we are going to pass a parameter k and divide the days we had into intervals #  #</code></a></li>
<li class="chapter" data-level="8" data-path="r-we-decided-that-7-days-would-be-a-nice-interval-to-keep-it-means-we-are-going-to-conduct-our-correlation-weekly.-of-course-we-could-change-k-to-14-k-7-do_interval-functiondfinterval-we-are-going-to-start-numerating-it-from-1-cause-we-need-to-create-a-new-column-c1-for-row-in-1nrowdf-dfrowinterval--floorcinterval1-we-increase-our-counter-and-divide-by-the-interval-parameter-so-that-for-each-day-we-have-the-correspondant-interval-in-a-separeted-column-cc1-here-we-are-going-to-aggregate-the-cases-deaths-or-other-metrics-based-on-the-intervals-the-conditions-that-we-put-on-the-number-of-columns-is-used-to-differentiate-the-different-data-sets-that-we-are-going-to-pass.-if-ncoldf6-ifncoldf14-ncoldf10-we-are-in-the-cases-and-deaths-table-here-summing-the-variables-on-grouping-by-the-interval-df-aggregatecbinddfcasesdfdeathsbylistdfintervalfunsum-colnamesdf1-interval-colnamesdf2-cases-colnamesdf3-deaths-else-we-are-in-the-travel-table-here-df-aggregatecbinddfc16bylistdfintervalfunsum-colnamesdf1-interval-else-we-"><a href="r-we-decided-that-7-days-would-be-a-nice-interval-to-keep-it-means-we-are-going-to-conduct-our-correlation-weekly.-of-course-we-could-change-k-to-14-k-7-do_interval-functiondfinterval-we-are-going-to-start-numerating-it-from-1-cause-we-need-to-create-a-new-column-c1-for-row-in-1nrowdf-dfrowinterval--floorcinterval1-we-increase-our-counter-and-divide-by-the-interval-parameter-so-that-for-each-day-we-have-the-correspondant-interval-in-a-separeted-column-cc1-here-we-are-going-to-aggregate-the-cases-deaths-or-other-metrics-based-on-the-intervals-the-conditions-that-we-put-on-the-number-of-columns-is-used-to-differentiate-the-different-data-sets-that-we-are-going-to-pass.-if-ncoldf6-ifncoldf14-ncoldf10-we-are-in-the-cases-and-deaths-table-here-summing-the-variables-on-grouping-by-the-interval-df-aggregatecbinddfcasesdfdeathsbylistdfintervalfunsum-colnamesdf1-interval-colnamesdf2-cases-colnamesdf3-deaths-else-we-are-in-the-travel-table-here-df-aggregatecbinddfc16bylistdfintervalfunsum-colnamesdf1-interval-else-we-"><i class="fa fa-check"></i><b>8</b> <code>{r} # #We decided that 7 days would be a nice interval to keep, it means we are going to conduct our correlation weekly. Of course we could change k to 14 # k&lt;-7 # do_interval&lt;-function(df,interval){ #   # we are going to start numerating it from 1 cause we need to create a new column #   c=1 # for (row in 1:nrow(df)){ #     df[row,'interval']&lt;- floor(c/interval)+1 #    # #We increase our counter and divide by the interval parameter so that for each day we have the correspondant interval in a separeted column # c=c+1 # } #  #here we are going to aggregate the cases, deaths or other metrics based on the intervals #   #The conditions that we put on the number of columns is used to differentiate the different data sets that we are going to pass.  #   if (ncol(df)&gt;6){ #      #     if(ncol(df)&lt;14 &amp; ncol(df)!=10){ #     # We are in the cases and deaths table here #     #summing the variables on grouping by the interval # df&lt;-aggregate(cbind(df$cases,df$deaths),by=list(df$interval),FUN=sum) # colnames(df)[1]&lt;-'interval' # colnames(df)[2]&lt;-'cases' # colnames(df)[3]&lt;-'deaths' #     }else{ #   #we are in the travel table here #   df&lt;-aggregate(cbind(df[c(1:6)]),by=list(df$interval),FUN=sum) #   colnames(df)[1]&lt;-'interval' # } # }else{ #   #we are in the tweet counts table here #   df&lt;-aggregate(df$tweet_counts,by=list(df$interval),FUN=sum) #   colnames(df)[1]&lt;-'interval' #   colnames(df)[2]&lt;-'tweet_counts' #   } #   return(df) # } # df31&lt;-do_interval(df3,k) # df32&lt;-do_interval(ciao1_mod3,k) # # we are going to merge by our interval, so then we can calculate correlation and plot the scatterplot and the best fitting line. # df3_final&lt;-merge(df31,df32,by=c('interval')) # corr1&lt;-cor(df3_final$cases, df3_final$tweet_counts) # cortest1&lt;-cor.test(df3_final$cases, df3_final$tweet_counts) # corr2&lt;-cor(df3_final$deaths, df3_final$tweet_counts) # cortest2&lt;-cor.test(df3_final$deaths, df3_final$tweet_counts) # ggplot(df3_final, aes(x = deaths, y = tweet_counts)) + geom_point(size = 0.5, alpha = 0.3, col='black') + scale_x_continuous(labels = scales::comma)+geom_smooth(method=lm) # ggplot(df3_final, aes(x = cases, y = tweet_counts)) + geom_point(size = 0.5, alpha = 0.3, col='red') + scale_x_continuous(labels = scales::comma)+geom_smooth(method=lm) # #visualizing the time series of the cases  # ggplot(df3_final,aes(x=interval))+ geom_line(aes(y=cases),size = 0.5, alpha = 0.3, col='red') + geom_line(aes(y=tweet_counts),size = 0.5, alpha = 0.3, col='blue')+scale_x_continuous(labels = scales::comma)+xlab('week')+ylab('Cases and tweet counts') # # we decided to divide by the average so to normalize our results and have a sense of what the correlation is # # in this case, the y axis is not useful, but we just observe the patterns # ggplot(df3_final,aes(x=interval))+ geom_line(aes(y=deaths/mean(deaths)),size = 0.5, alpha = 0.3, col='red') + geom_line(aes(y=tweet_counts/mean(tweet_counts)),size = 0.5, alpha = 0.3, col='blue')+scale_x_continuous(labels = scales::comma)+xlab('week')+ylab('Proportions of deaths and tweet counts') #</code></a></li>
<li class="chapter" data-level="9" data-path="observations.-if-we-take-a-look-at-our-correlations-coefficient-we-can-see-two-different-stories.-when-it-comes-to-number-of-covid-related-tweets-in-relation-to-the-number-of-deaths-we-have-low-correlation-.-the-correlation-coefficient-is-this-case-is-0.21corr2-which-means-there-is-a-positive-correlation.-however-if-we-take-a-look-at-the-correlation-test-cortest2-we-can-see-that-the-pvalue-is-0.1951-hence-even-with-a-confidence-level-of-10-we-cannot-reject-the-null-hypothesis-that-the-correlation-happened-by-chance..html"><a href="observations.-if-we-take-a-look-at-our-correlations-coefficient-we-can-see-two-different-stories.-when-it-comes-to-number-of-covid-related-tweets-in-relation-to-the-number-of-deaths-we-have-low-correlation-.-the-correlation-coefficient-is-this-case-is-0.21corr2-which-means-there-is-a-positive-correlation.-however-if-we-take-a-look-at-the-correlation-test-cortest2-we-can-see-that-the-pvalue-is-0.1951-hence-even-with-a-confidence-level-of-10-we-cannot-reject-the-null-hypothesis-that-the-correlation-happened-by-chance..html"><i class="fa fa-check"></i><b>9</b> Observations. If we take a look at our correlations coefficient we can see two different stories. When it comes to number of covid-related tweets in relation to the number of deaths we have low correlation . The correlation coefficient is this case is 0.21(corr2), which means there is a positive correlation. However if we take a look at the correlation test cortest2 we can see that the pvalue is 0.1951, hence even with a confidence level of 10% we cannot reject the null hypothesis that the correlation happened by chance.</a></li>
<li class="chapter" data-level="10" data-path="on-the-other-hand-we-can-analyse-our-correlation-of-cases-and-number-of-tweets.in-corr1-we-have-stored-a-correlation-value-of--0.48-and-the-associated-pvalue-is-0.0025-which-means-we-can-reject-our-null-hypothesis-and-state-that-there-is-a-correlation-between-the-number-of-cases-and-number-of-tweets..html"><a href="on-the-other-hand-we-can-analyse-our-correlation-of-cases-and-number-of-tweets.in-corr1-we-have-stored-a-correlation-value-of--0.48-and-the-associated-pvalue-is-0.0025-which-means-we-can-reject-our-null-hypothesis-and-state-that-there-is-a-correlation-between-the-number-of-cases-and-number-of-tweets..html"><i class="fa fa-check"></i><b>10</b> On the other hand, we can analyse our correlation of cases and number of tweets.In corr1 we have stored a correlation value of -0.48 and the associated pvalue is 0.0025, which means we can reject our null hypothesis and state that there is a correlation between the number of cases and number of tweets.</a></li>
<li class="chapter" data-level="11" data-path="the-surprising-feature-is-that-the-correlation-is-negative-where-common-sense-may-suggest-there-would-be-a-positive-correlation.in-other-words-we-may-expect-higher-number-of-cases-could-trigger-a-higher-number-of-people-talking-about-it..html"><a href="the-surprising-feature-is-that-the-correlation-is-negative-where-common-sense-may-suggest-there-would-be-a-positive-correlation.in-other-words-we-may-expect-higher-number-of-cases-could-trigger-a-higher-number-of-people-talking-about-it..html"><i class="fa fa-check"></i><b>11</b> The surprising feature, is that the correlation is negative, where common sense may suggest there would be a positive correlation.In other words, we may expect, higher number of cases could trigger a higher number of people talking about it.</a></li>
<li class="chapter" data-level="12" data-path="the-truth-may-be-another-one.-we-suspect-that-the-real-correlation-may-be-linked-to-the-dates-itself.-as-we-can-see-in-the-interval-chart-we-have-that-in-the-first-5-weeks-start-date-412020-people-were-more-scared-and-more-prone-to-talk-about-it-then-as-the-virus-became-usual-among-our-lives-the-covid-tweets-chat-started-to-slowly-but-steadily-decline.-even-in-the-last-part-of-the-graph-when-cases-started-taking-off-exponentially-the-number-of-covid-related-tweets-continued-to-slow..html"><a href="the-truth-may-be-another-one.-we-suspect-that-the-real-correlation-may-be-linked-to-the-dates-itself.-as-we-can-see-in-the-interval-chart-we-have-that-in-the-first-5-weeks-start-date-412020-people-were-more-scared-and-more-prone-to-talk-about-it-then-as-the-virus-became-usual-among-our-lives-the-covid-tweets-chat-started-to-slowly-but-steadily-decline.-even-in-the-last-part-of-the-graph-when-cases-started-taking-off-exponentially-the-number-of-covid-related-tweets-continued-to-slow..html"><i class="fa fa-check"></i><b>12</b> The truth may be another one. We suspect that the real correlation may be linked to the dates itself. As we can see in the interval chart, we have that in the first 5 weeks (start date 4/1/2020), people were more scared and more prone to talk about it, then as the virus became usual among our lives, the covid tweets chat started to slowly but steadily decline. Even in the last part of the graph, when cases started taking off exponentially, the number of covid related tweets continued to slow.</a></li>
<li class="chapter" data-level="13" data-path="section-1.html"><a href="section-1.html"><i class="fa fa-check"></i><b>13</b> </a></li>
<li class="chapter" data-level="14" data-path="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc"><a href="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc"><i class="fa fa-check"></i><b>14</b> <code>{r} # # In movements we have the changing for percentage of transit of people in comparison to same period of time in 2019in the whole USA # dfmove&lt;-Movements # # We have to convert the dates that we have in a more suitable format so that we can use the comparison to other dfs # for (row in 1:nrow(dfmove)){ #    #     date&lt;-dfmove[row,'date'] #     arr&lt;-strsplit(date,split='-') #     dfmove[row,'year']=(arr[[1]][1]) #     dfmove[row,'month']=(arr[[1]][2]) #     dfmove[row,'day']=(arr[[1]][3]) #    # dfmove[row,'day']=strtoi(arr[[1]][3]) # } #  # dfmove$year&lt;-as.integer(dfmove$year) # dfmove$month&lt;-as.integer(dfmove$month) # dfmove$day&lt;-as.integer(dfmove$day) # dfmove&lt;-dfmove[dfmove$month&gt;=4 &amp; dfmove$year==2020,] # n&lt;-dim(dfmove)[1] # dfmove&lt;-dfmove[1:(n-18),] # # we are going to get the columns that we need, cleaning the data from useless columns # dfmove$interval&lt;-0 # dfmove&lt;-dfmove[c(10:19)] # #We order them by the date so we can use the function do_interval and compare the results # dfmove&lt;-dfmove[order(dfmove$year,dfmove$month,dfmove$day),] # dfmove %&gt;% map_df(rev) # dfmovem&lt;-do_interval(dfmove,k) # #To have the correct change over the period, we are going to divide the columns by the period #  # dfmovem[2:7]&lt;-dfmovem[,2:7]/k #  # df4final&lt;-merge(dfmovem,df32,by=c('interval')) # df4final1&lt;-merge(dfmovem,df31,by=c('interval')) # #We set a parameter so that we can easily change for our visualization # x1&lt;-df4final$retail_and_recreation_percent_change_from_baseline # corr41&lt;-cor(x1, df4final$tweet_counts) # cortest41&lt;-cor.test(x1, df4final$tweet_counts) # corr42&lt;-cor(x1, df4final1$cases) # cortest42&lt;-cor.test(x1, df4final1$cases) # ggplot(df4final, aes(x = x1, y = tweet_counts)) + geom_point(size = 0.5, alpha = 0.3, col='black') + scale_x_continuous(labels = scales::comma)+geom_smooth(method=lm) # ggplot(df4final1, aes(x=df4final1$cases, y = x1)) + geom_point(size = 0.5, alpha = 0.3, col='black') + scale_x_continuous(labels = scales::comma)+geom_smooth(method=lm) # #create a ridgepllot with the different  # #pivoted&lt;-pivot_longer(df4final,cols = #c(df4final$retail_and_recreation_percent_change_from_baseline,df4final$grocery_and_pharmacy_percent_change_from_basel#ine,df4final$parks_percent_change_from_baseline,df4final$transit_stations_percent_change_from_baseline,df4final$workp#laces_percent_change_from_baseline,df4final$residential_percent_change_from_baseline),names_to = 'type',values_to = #'vals')</code></a>
<ul>
<li class="chapter" data-level="14.1" data-path="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc"><a href="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc#covid-vs.-mobility"><i class="fa fa-check"></i><b>14.1</b> COVID vs. Mobility</a></li>
<li class="chapter" data-level="14.2" data-path="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc"><a href="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc#analyzing-the-policy-of-representatives-of-congress-through-their-tweets"><i class="fa fa-check"></i><b>14.2</b> Analyzing the policy of representatives of Congress through their tweets</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc"><a href="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc#extracting-the-data"><i class="fa fa-check"></i><b>14.2.1</b> Extracting the data</a></li>
<li class="chapter" data-level="14.2.2" data-path="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc"><a href="r-in-movements-we-have-the-changing-for-percentage-of-transit-of-people-in-comparison-to-same-period-of-time-in-2019in-the-whole-usa-dfmove-movements-we-have-to-convert-the-dates-that-we-have-in-a-more-suitable-format-so-that-we-can-use-the-comparison-to-other-dfs-for-row-in-1nrowdfmove-date-dfmoverowdate-arr-strsplitdatesplit--dfmoverowyeararr11-dfmoverowmontharr12-dfmoverowdayarr13-dfmoverowdaystrtoiarr13-dfmoveyear-as.integerdfmoveyear-dfmovemonth-as.integerdfmovemonth-dfmoveday-as.integerdfmoveday-dfmove-dfmovedfmovemonth4-dfmoveyear2020-n-dimdfmove1-dfmove-dfmove1n-18-we-are-going-to-get-the-columns-that-we-need-cleaning-the-data-from-useless-columns-dfmoveinterval-0-dfmove-dfmovec1019-we-order-them-by-the-date-so-we-can-use-the-function-do_interval-and-compare-the-results-dfmove-dfmoveorderdfmoveyeardfmovemonthdfmoveday-dfmove-map_dfrev-dfmovem-do_intervaldfmovek-to-have-the-correct-change-over-the-period-we-are-going-to-divide-the-columns-by-the-period-dfmovem27-dfmovem27k-df4final-mergedfmovemdf32byc#patterns-in-policy"><i class="fa fa-check"></i><b>14.2.2</b> Patterns in policy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="interactive-component.html"><a href="interactive-component.html"><i class="fa fa-check"></i><b>15</b> Interactive component</a></li>
<li class="chapter" data-level="16" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>16</b> Conclusion</a>
<ul>
<li class="chapter" data-level="16.1" data-path="conclusion.html"><a href="conclusion.html#covid-19-vs-mobility-for-us-congress-members"><i class="fa fa-check"></i><b>16.1</b> COVID-19 vs Mobility for US Congress Members</a></li>
<li class="chapter" data-level="16.2" data-path="conclusion.html"><a href="conclusion.html#policy-related-tweets"><i class="fa fa-check"></i><b>16.2</b> Policy Related Tweets</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">US Congress - Tweets and COVID-19</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-sources" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Data sources</h1>
<ul>
<li><a href="https://github.com/unitedstates/congress-legislators/" class="uri">https://github.com/unitedstates/congress-legislators/</a></li>
<li><a href="https://github.com/thepanacealab/covid19_twitter" class="uri">https://github.com/thepanacealab/covid19_twitter</a></li>
<li><a href="https://ieee-dataport.org/open-access/coronavirus-covid-19-geo-tagged-tweets-dataset" class="uri">https://ieee-dataport.org/open-access/coronavirus-covid-19-geo-tagged-tweets-dataset</a></li>
<li><a href="https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide" class="uri">https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide</a></li>
</ul>
<div id="congress-members-tweets" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Congress Members Tweets</h2>
<p>Since there are a lot of tweets and we don’t have a developer account such that we could retrieve millions of tweets successfully, we opted to get the most basic information for each tweet. We retrieved the user’s handle (i.e. username), the content of the tweet, geolocation data if any, the tweet id, and the language in which the tweet was written as determined by Twitter. If a language cannot be identified it is labeled as “und”. This label is a bit misleading at times, but this issue is discussed further in the Missing Data section of this report. We limited our search to tweets from handles according to (this)[<a href="https://github.com/unitedstates/congress-legislators/" class="uri">https://github.com/unitedstates/congress-legislators/</a>] dataset of Twitter handles for each congress member. We also limited our search to tweets from 12:00 AM UTC 2020 to 11:59 PM UTC 2020. These seemed like reasonable bounds since COVID-19 was particularly virulent in the year 2020 and the vaccine was not widely available before 2021 either. There were other features we could get from Twitter such as an entities object and sentiment analysis. We felt that the utility of these sentiments was not worth the extra time it would take to retrieve and parse through those fields. Moreover, we can still choose NLP models differing from those used by Twitter to extract information from tweet content. Thus extracting this information at the outset was not necessary, but comparing twitter sentiments and entities to those from other models could be useful in future work.</p>
</div>
<div id="googles-changes-in-mobility-data" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Google’s Changes in Mobility Data</h2>
<p>There is not much we can change or alter about this dataset and it is quite robust. The gist of the dataset is that Google used it’s geolocation data from its various users and services to determine relative changes in mobility between categories of places. These categories include: Retail &amp; Recreation Grocery &amp; Pharmacy, Parks, Transit Stations, Workplaces, and Residential. Obviously, this is not a comprehensive list of all categories of places where people may congregate, but it is nonetheless a representative sample of places where we would expect a high volume of human traffic. Other places which are not included which could be useful to inquire about are large conventions. Even if they are less frequent, the high concentration of people and relative changes therein may have an outsized impact on COVID-19. This could be a useful follow-up to this project but separate data may need to be sourced or scraped from the web.</p>
</div>
<div id="number-of-tweets-cases-and-mobility" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Number of tweets cases and mobility</h2>
<p>The data sources we used for this part were the ecdc dataset about the COVID-19 cases and deaths during 2020 and the twitter data. In the first case, we filtered the table just to include the USA data, so that we could have a table diplaying date, number of cases, and deaths for each day. To better compare our data, we just focused on the prevaccine covid situation, starting from the 4/1/2020 till around 12/15/2020. For the twitter data, we had to webscrape the parts that we needed. The original dataset had the top 1000 bigrams in terms of occurrence for each day . To ease up our processes we decided to include only the top 50 most used covid-related bigrams.Furthermore, we also used the mobility data for general USA overview, that was webscraped previously.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-transformation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dgorhe/us_congress_twitter_covid/edit/main/02-data.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/dgorhe/us_congress_twitter_covid/blob/main/02-data.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
